{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77222fbc",
   "metadata": {},
   "source": [
    "setup a framework for the pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b5af8",
   "metadata": {},
   "source": [
    "multi-rater annotations + weak annotated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b84b69",
   "metadata": {},
   "source": [
    "based on nnUNet v2, combining Transformer-based UNet, such as swinUNet and TransUNet, or foundation model as encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e7315",
   "metadata": {},
   "source": [
    "uncertainty awareness training(Monte Carlo dropout or ensemble output distribution) + soft labels for multi-annotation combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c9c4c",
   "metadata": {},
   "source": [
    "swinUNet -> https://github.com/HuCaoFighting/Swin-Unet\n",
    "with pretrained model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ac51a",
   "metadata": {},
   "source": [
    "@InProceedings{swinunet,\n",
    "author = {Hu Cao and Yueyue Wang and Joy Chen and Dongsheng Jiang and Xiaopeng Zhang and Qi Tian and Manning Wang},\n",
    "title = {Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation},\n",
    "booktitle = {Proceedings of the European Conference on Computer Vision Workshops(ECCVW)},\n",
    "year = {2022}\n",
    "}\n",
    "\n",
    "@misc{cao2021swinunet,\n",
    "      title={Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation}, \n",
    "      author={Hu Cao and Yueyue Wang and Joy Chen and Dongsheng Jiang and Xiaopeng Zhang and Qi Tian and Manning Wang},\n",
    "      year={2021},\n",
    "      eprint={2105.05537},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={eess.IV}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# ---------------------------\n",
    "# Swin Transformer Block\n",
    "# ---------------------------\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
    "        self.attn_proj = nn.Linear(dim, dim)\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
    "        q, k, v = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        return self.attn_proj(out)\n",
    "\n",
    "# dropout block can be added to the SwinBlock module\n",
    "class SwinBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, mlp_ratio=4.):\n",
    "    # def __init__(self, dim, input_resolution, num_heads, window_size=7, mlp_ratio=4., dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = WindowAttention(dim, window_size, num_heads)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, int(dim * mlp_ratio)),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(dropout_rate),\n",
    "            nn.Linear(int(dim * mlp_ratio), dim)\n",
    "            # nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x) + x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Patch Embedding\n",
    "# ---------------------------\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=1, embed_dim=96):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)  # B C H W\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Patch Merging\n",
    "# ---------------------------\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim)\n",
    "        self.norm = nn.LayerNorm(4 * dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, L, C = x.shape\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # (B H/2 W/2 C)\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4C\n",
    "        x = x.view(B, -1, 4 * C)\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Swin UNet Encoder-Decoder\n",
    "# ---------------------------\n",
    "class SwinUNet(nn.Module):\n",
    "    def __init__(self, img_size=224, in_chans=1, num_classes=2, embed_dim=96):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbed(img_size, patch_size=4, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        self.stage1 = SwinBlock(embed_dim, img_size // 4, num_heads=3)\n",
    "        self.down1 = PatchMerging(embed_dim)\n",
    "\n",
    "        self.stage2 = SwinBlock(embed_dim * 2, img_size // 8, num_heads=6)\n",
    "        self.down2 = PatchMerging(embed_dim * 2)\n",
    "\n",
    "        self.bottleneck = SwinBlock(embed_dim * 4, img_size // 16, num_heads=12)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(embed_dim * 4, embed_dim * 2, kernel_size=2, stride=2)\n",
    "        self.decoder1 = nn.Conv2d(embed_dim * 4, embed_dim * 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(embed_dim * 2, embed_dim, kernel_size=2, stride=2)\n",
    "        self.decoder2 = nn.Conv2d(embed_dim * 2, embed_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        self.final = nn.Conv2d(embed_dim, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        H, W = x.shape[2], x.shape[3]\n",
    "\n",
    "        x = self.patch_embed(x)  # B, L, C\n",
    "        x1 = self.stage1(x)\n",
    "        x2 = self.down1(x1, H // 4, W // 4)\n",
    "\n",
    "        x3 = self.stage2(x2)\n",
    "        x4 = self.down2(x3, H // 8, W // 8)\n",
    "\n",
    "        x5 = self.bottleneck(x4)\n",
    "\n",
    "        # reshape\n",
    "        x5_up = x5.transpose(1, 2).reshape(B, -1, H // 8, W // 8)\n",
    "        x3_up = x3.transpose(1, 2).reshape(B, -1, H // 8, W // 8)\n",
    "        x = torch.cat([self.up1(x5_up), x3_up], dim=1)\n",
    "        x = self.decoder1(x)\n",
    "\n",
    "        x1_up = x1.transpose(1, 2).reshape(B, -1, H // 4, W // 4)\n",
    "        x = torch.cat([self.up2(x), x1_up], dim=1)\n",
    "        x = self.decoder2(x)\n",
    "\n",
    "        out = self.final(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = SwinUNet(img_size=224, in_chans=1, num_classes=2)\n",
    "    x = torch.randn(1, 1, 224, 224)\n",
    "    y = model(x)\n",
    "    print(\"Output shape:\", y.shape)  # (1, 2, 224, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172a6abc",
   "metadata": {},
   "source": [
    "Pipline: \n",
    "\n",
    "-data preprocessing\n",
    "\n",
    "-reader and writer: read CT data and write it into the swinUNet input form\n",
    "\n",
    "-model building\n",
    "\n",
    "-model training: design loss, tuning, evaluation\n",
    "\n",
    "-model test:\n",
    "\n",
    "-postprocessing\n",
    "\n",
    "-experiment planning? ensembling? dataset conversion? benchmarking?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38990c1",
   "metadata": {},
   "source": [
    "Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\"\n",
    "    Imply Dropout in inference\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979ebde",
   "metadata": {},
   "source": [
    "MC Dropout inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e19e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mc_dropout_inference(model, x, T=10):\n",
    "    \"\"\"\n",
    "    Imply T times MC Dropout inference to input x\n",
    "    return mean and std for prediction result and uncertainty\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    enable_dropout(model)\n",
    "\n",
    "    preds = []\n",
    "    for _ in range(T):\n",
    "        out = model(x)  # (B, C, H, W)\n",
    "        preds.append(torch.softmax(out, dim=1))  # softmax 处理多分类概率\n",
    "\n",
    "    preds = torch.stack(preds)  # (T, B, C, H, W)\n",
    "    mean_pred = preds.mean(dim=0)\n",
    "    std_pred = preds.std(dim=0)\n",
    "    return mean_pred, std_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f71b69",
   "metadata": {},
   "source": [
    "imply example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNet(...)\n",
    "x = torch.randn(1, 1, 224, 224).cuda()\n",
    "mean_pred, std_pred = mc_dropout_inference(model, x, T=20)\n",
    "\n",
    "# Visualization：\n",
    "# mean_pred.argmax(dim=1) -> most possible class\n",
    "# std_pred -> Uncertainty Heat Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d05a9",
   "metadata": {},
   "source": [
    "MODEL ENSEMBLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, x):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(x)\n",
    "            preds.append(torch.softmax(out, dim=1))\n",
    "    preds = torch.stack(preds)  # (N, B, C, H, W)\n",
    "    mean_pred = preds.mean(dim=0)\n",
    "    std_pred = preds.std(dim=0)\n",
    "    return mean_pred, std_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfef365",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SwinUNet(...).cuda() for _ in range(5)]\n",
    "\n",
    "# loading models with various weights or from different initialization training\n",
    "for i, m in enumerate(models):\n",
    "    m.load_state_dict(torch.load(f\"model_{i}.pth\"))\n",
    "\n",
    "x = torch.randn(1, 1, 224, 224).cuda()\n",
    "mean_pred, std_pred = ensemble_predict(models, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95640379",
   "metadata": {},
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize prediction classes\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Prediction\")\n",
    "plt.imshow(mean_pred[0].argmax(dim=0).cpu(), cmap='gray')\n",
    "\n",
    "# visualize uncertainty - std\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Uncertainty (std)\")\n",
    "plt.imshow(std_pred[0].mean(dim=0).cpu(), cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fcae68",
   "metadata": {},
   "source": [
    "tips:\n",
    "1. swinUNet 有pretrained模型\n",
    "2. 24有许多接口文件，这个我们需要吗？\n",
    "3. 24有方便用户使用的端口设计，我们需要吗，以及这个可以参考他们的设计吗？\n",
    "4. 实验配置器设计？\n",
    "5. data conversion - 定制swinUNet的数据格式，以及匹配soft label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d5fc6",
   "metadata": {},
   "source": [
    "1. timeline\n",
    "2. 跑通模型\n",
    "3. github上传所有改动"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abpco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
